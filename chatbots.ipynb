{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model=\"Gemma2-9b-It\",groq_api_key=groq_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Fahim! \\n\\nIt's great to meet you. Don't worry about being a noob in AI тАУ everyone starts somewhere! \\n\\nAI is a fascinating field with a lot to learn, but it's also incredibly rewarding.\\n\\nWhat are you most interested in learning about AI? \\n\\nMaybe I can give you some resources or answer some basic questions to get you started. ЁЯШД\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 84, 'prompt_tokens': 21, 'total_tokens': 105, 'completion_time': 0.152727273, 'prompt_time': 0.000147669, 'queue_time': 0.002949331, 'total_time': 0.152874942}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-eb9c86a5-3119-4a3e-829c-7aed2051f281-0', usage_metadata={'input_tokens': 21, 'output_tokens': 84, 'total_tokens': 105})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"HI My name is Fahim, I am noob in AI\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "response = model.invoke([\n",
    "    HumanMessage(content=\"HI Im fahim and im noob in AI\"),\n",
    "    AIMessage(content=\"Hello Fahim! \\n\\nIt's great to meet you. Don't worry about being a noob in AI, everyone starts somewhere. It's a fascinating field with a lot to learn, but it's also very rewarding\"),\n",
    "    HumanMessage(content=\"What is my name\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is Fahim, as you told me at the beginning of our conversation. ЁЯШК  \n",
      "\n",
      "Is there anything else I can help you with today, Fahim? \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser = StrOutputParser()\n",
    "\n",
    "result = parser.invoke(response)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Message History\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "store = {}\n",
    "def get_session_history(session_id:str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"HI,I am Fahim and I am a frontend developer\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hey Fahim! \\n\\nWelcome!  It's great to have another frontend developer in the mix.  \\n\\nWhat are you working on these days? Any exciting projects you're excited about? ЁЯШД ЁЯТ╗  \\n\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "response2 = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Fahim. ЁЯШД  \\n\\nI remember!  We met earlier.  What can I help you with today?\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing the sessionId\n",
    "\n",
    "config2={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response2 = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name\")],\n",
    "    config=config2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I have no memory of past conversations and do not know your name. If you'd like to tell me, I'd be happy to use it!\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "response3 = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"My name is John\")],\n",
    "    config=config2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is John.  \\n\\nIs there anything else I can help you with? ЁЯШК  \\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response4 = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name\")],\n",
    "    config=config2\n",
    ")\n",
    "\n",
    "response4.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant answer the questions which are being asked\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Fahim, it's nice to meet you! ЁЯСЛ\\n\\nHow can I help you today? ЁЯШК  Ask me anything! \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 27, 'total_tokens': 59, 'completion_time': 0.058181818, 'prompt_time': 0.000166909, 'queue_time': 0.002970761, 'total_time': 0.058348727}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-84ec7ac6-f018-4bbd-832e-85836efc8840-0', usage_metadata={'input_tokens': 27, 'output_tokens': 32, 'total_tokens': 59})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\": [HumanMessage(content=\"HI My name is fahim\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "config3={\"configurable\":{\"session_id\":\"chat3\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what is my name\")],\n",
    "    config=config3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As a helpful assistant, I don't have access to any personal information about you, including your name.  If you'd like to tell me your name, I'd be happy to know! ЁЯШК  \\n\\n\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addding more complexity\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant reply to the question using this {language}\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"messages\":[HumanMessage(content=\"HI I am Fahim and i dont know what to do in life\")],\"language\":\"Tamil\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ро╡рогроХрпНроХроорпН Fahim!  \\n\\nроЙройрпНройрпИрокрпН рокрпКро░рпБродрпНродро╡ро░рпИ ро╡ро╛ро┤рпНроХрпНроХрпИропро┐ро▓рпН роОройрпНрой роЪрпЖропрпНроп ро╡рпЗрогрпНроЯрпБроорпН роОройрпНрокродрпБ роХрпБро▒ро┐родрпНродрпБ родрпЖро│ро┐ро╡ро┐ро▓рпНро▓ро╛родродрпБ роОройрпНрокродрпБ рокрпБро░ро┐ропро▓ро╛роорпН.  роХро╡ро▓рпИрокрпНрокроЯро╛род, роЗродрпБ роТро░рпБ рокрпКродрпБро╡ро╛рой роЪроирпНродрпЗроХроорпН. \\n\\nроорпЗро▓рпБроорпН роЙройрпНройро┐роЯроорпН роЪро┐ро▓ роХрпЗро│рпНро╡ро┐роХро│рпБроЯройрпН роЙродро╡рпБро╡рпЗройрпН:\\n\\n* **роирпА роОройрпНройрокрпН рокроЯро┐роХрпНроХро┐ро▒ро╛ропрпН/рокроЯро┐родрпНродро┐ро░рпБроХрпНроХро┐ро▒ро╛ропрпН?** \\n* **роЙройроХрпНроХрпБ роОроирпНрод ро╡ро┐ро╖ропроЩрпНроХро│ро┐ро▓рпН роЖро░рпНро╡роорпН роЗро░рпБроХрпНроХро┐ро▒родрпБ?** \\n* **роирпА роОройрпНрой рокрогро┐ропро┐ро▓рпН роЪрпЗро░рпБро╡родрпБ родрпВрогрпНроЯрпБроХро┐ро▒родрпБ?** \\n* **роирпА роХро╡ройроорпН роЪрпЖро▓рпБродрпНродрпБроорпН рокрпЛродрпБ роЙройроХрпНроХрпБ роороХро┐ро┤рпНроЪрпНроЪро┐ропрпИродрпН родро░рпБыКФ ро╡ро┐ро╖ропроЩрпНроХро│рпН роОройрпНрой?**\\n\\nроЙройродрпБ рокродро┐ро▓рпНроХро│рпИ роЕроЯро┐рокрпНрокроЯрпИропро╛роХроХрпН роХрпКрогрпНроЯрпБ, роЙроЩрпНроХро│рпБроХрпНроХро╛роХ роЪро┐ро▓ ро╡ро┤ро┐роХро╛роЯрпНроЯро┐роХро│рпИродрпН родро░рпБроХро┐ро▒рпЗройрпН.  роЙройродрпБ роЖро░рпНро╡роЩрпНроХро│рпБроХрпНроХрпЗро▒рпНрок рокроЯро┐рокрпНрокрпБ, ро╡рпЗро▓рпИ, роЕро▓рпНро▓родрпБ рокрпКродрпБ роиро▓ рокрогро┐роХро│ро┐ро▓рпН роИроЯрпБрокроЯро▓ро╛роорпН. \\n\\nро╡ро╛ро┤рпНроХрпНроХрпИ роТро░рпБ рокропрогроорпН, роЕродро┐ро▓рпН роЪро░ро┐ропро╛рой ро╡ро┤ро┐ропрпИродрпН родрпЗроЯ ро╡рпЗрогрпНроЯро┐ропродрпБ роЕро╡роЪро┐ропроорпН.  роЙройрпНройрпБроЯрпИроп роЪроХрпНродро┐роХро│рпИропрпБроорпН роЖро░рпНро╡роЩрпНроХро│рпИропрпБроорпН роЕро▒ро┐ропрпБроорпНрокрпЛродрпБ,  \\nроЙройрпНройрпИрокрпН рокрпКро░рпБродрпНродрооро╛рой ро╡ро╛ро┤рпНроХрпНроХрпИрокрпН рокро╛родрпИропрпИродрпН родрпАро░рпНрооро╛ройро┐роХрпНроХ роорпБроЯро┐ропрпБроорпН. \\n\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'##  GATE Mechanical Engineering: Scoring Strategy \\n\\nро╡рогроХрпНроХроорпН! Mechanical Engineering GATE exam-роХрпНроХрпБ родропро╛ро░ро╛роХро┐ роЗро░рпБроХрпНроХрпАроЩрпНроХро│рпЗ! Good marks score роЪрпЖропрпНроп  роЙродро╡рпБроорпН роЪро┐ро▒роирпНрод  stratgey роЩрпНроХ  роХрпАро┤рпЗ роЙро│рпНро│рой:\\n\\n**родрпКроЯроХрпНроХродрпНродро┐ро▓рпН:**\\n\\n* **Syllabus-ро▓  роЪро░ро┐  роЪро░ро┐ рокро╛ро░рпН:** GATE syllabus-ройрпИ  роиройрпНроХрпБ  рокрпБро░ро┐роирпНродрпБроХрпКро│рпНро│рпБроЩрпНроХро│рпН.  роЕродро┐ро▓рпН роОроирпНрод роЕродрпНродро┐ропро╛ропроЩрпНроХро│рпН  роОродрпБро╡рпБроорпН роЗро▓рпНро▓ро╛род  роОройрпНрокродрпИ  рокро╛ро░рпБроЩрпНроХро│рпН.\\n* **Referred Books & Materials:**  роиро▓рпНро▓ рокрпБродрпНродроХроЩрпНроХро│рпН  роОроЯрпБродрпНродрпБроХрпНроХрпКро│рпНро│рпБроЩрпНроХро│рпН.  Previous year papers, sample papers, mock tests  роЗро▓рпНро▓ро╛рооро▓рпН роЗро░рпБроХрпНроХро╡рпЗ  родрпБро▓рпНро▓ро┐ропроорпН роЗро▓рпНро▓рпИропрпЗ! \\n* **Time Management:**  роТро╡рпНро╡рпКро░рпБ  роЕродрпНродро┐ропро╛ропродрпНродро┐ро▒рпНроХрпБроорпН  роЪро░ро┐ропро╛рой  роирпЗро░роорпН  роирпАроЯрпНроЯро┐роХрпНроХрпКро│рпНро│рпБроЩрпНроХро│рпН. \\n\\n**рокроЯро┐рокрпНрокродро▒рпНроХрпБ роорпБроХрпНроХро┐ропроорпН:**\\n\\n* **Concept Clarity:** ыЛиьИЬэЮИ  родрпКроЯро░рпНроирпНродрпБ  роОро┤рпБродрпБро╡родрпБ  роороЯрпНроЯрпБроорпН  роЗро▓рпНро▓рпИ,  conceept-ро▓  роиройрпНроХрпБ  рокрпБро░ро┐роирпНродрпБроХрпКро│рпНро│рпБроЩрпНроХро│рпН.\\n* **Practice Problems:**  роОро▓рпНро▓ро╛  роХрпКроЯрпБроХрпНроХрокрпНрокроЯрпНроЯ  probelms-ро▓рпБроорпН  роЪрпЛродро┐родрпНродрпБрокрпН  рокро╛ро░рпНроХрпНроХро╡рпБроорпН. \\n* **Revision:**  роЪро┐ро▒роирпНрод  revision  роорпВро▓роорпН   роОро▓рпНро▓ро╛  роЕродрпНродро┐ропро╛ропроЩрпНроХро│рпН  роорпВро▓роорпН  роиройрпНроХрпБ  рокрпЖро▒рпБроЩрпНроХро│рпН.\\n\\n**Exam Time:**\\n\\n* **Question Paper Analysis:**  exam  родрпКроЯроЩрпНроХрпБроорпН  роорпБройрпН,  question paper-роР  роиройрпНроХрпБ  рокроЯро┐родрпНродрпБ  роиро┐ройрпИроХрпНроХро╡рпБроорпН.\\n* **Time Allocation:**  роЪро░ро┐ропро╛рой  роирпЗро░роорпН  роТродрпБроХрпНроХро┐  questions-роХрпНроХрпБ  родрпАро░рпНро╡рпБ  роХро╛рогро╡рпБроорпН. \\n* **Stay Calm:**  exam  роирпЗро░родрпНродро┐ро▓рпН  stress  роХрпКро│рпНро│ро╛родрпАро░рпНроХро│рпН.  \\n\\n**Extra Tips:**\\n\\n* **Join Coaching Classes:**  роиро▓рпНро▓  coaching  classes-ро▓рпН  роЪрпЗро░рпБроЩрпНроХро│рпН. \\n* **Join Study Groups:**  роЗройрпНройрпКро░рпБ  рокро┐ро░ро┐ро╡ро┐ройрпН  рокроЯро┐рокрпНрокро╛ро│ро░рпНроХро│рпБроЯройрпН  роЪрпЗро░рпБроЩрпНроХро│рпН. \\n* **Mock Tests:**  mock tests-ро▓  роЪрпЛродро┐родрпНродрпБ  рокро╛ро░рпНрокрпНрокродрпБ  роЙроЩрпНроХро│рпБроХрпНроХрпБ  рооро┐роХро╡рпБроорпН  роЙродро╡рпБроорпН. \\n\\n\\n\\nроЗрокрпНрокроЯро┐ропрпЖро▓рпНро▓ро╛роорпН  роЪро░ро┐ропро╛рой  preparation  роЪрпЖропрпНродро╛ро▓рпН,  роЙроЩрпНроХро│рпБроХрпНроХрпБ  рооро┐роХ  роЪро┐ро▒роирпНрод  marks  рокрпЖро▒  роорпБроЯро┐ропрпБроорпН! All the best!\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"messages\":[HumanMessage(content=\"Im preparing for mechanical engineering gate. How to score good marks. give me some strategy\")],\"language\":\"Tamil\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add more complexity\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Fahim!  \\n\\nI'm glad you said hello!  ЁЯШК  What's on your mind today? \\n\\n\\n\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config4={\"configurable\":{\"session_id\":\"chat4\"}}\n",
    "response5 = with_message_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"Hi  i am fahim\")],\"language\":\"hindi\"},\n",
    "    config=config4\n",
    ")\n",
    "response5.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Managing the conversation History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "#trim_messages - helper to reduce how many messages we are sending to the model\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=70,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a good assistant', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Hi I am john', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hi John', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What is 4+5', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='The answer is 10', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What is 4-5', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='The answer is -1', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What is 4*5', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='The answer is 20', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You are a good assistant\"),\n",
    "    HumanMessage(content=\"Hi I am john\"),\n",
    "    AIMessage(content=\"Hi John\"),\n",
    "    HumanMessage(content=\"I like ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"What is 4+5\"),\n",
    "    AIMessage(content=\"The answer is 10\"),\n",
    "     HumanMessage(content=\"What is 4-5\"),\n",
    "    AIMessage(content=\"The answer is -1\"),\n",
    "         HumanMessage(content=\"What is 4*5\"),\n",
    "    AIMessage(content=\"The answer is 20\"),\n",
    "]\n",
    "trimmer.invoke(messages) \n",
    "# If you change the token size, it trims the the messages content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages=itemgetter('messages')|trimmer)\n",
    "    |prompt\n",
    "    |model\n",
    ")\n",
    "\n",
    "response6 = chain.invoke({\n",
    "    \"messages\":messages + [HumanMessage(content=\"What is my name\")],\n",
    "    \"language\":\"English\"\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I don't have access to past conversations or any personal information about you, including your name.  \\n\\nIf you'd like to tell me your name, I'd be happy to know! ЁЯШК  \\n\\n\""
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response6.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked:\\n\\n* What is 4 + 5 ?\\n* What is 4 - 5 ?\\n* What is 4 * 5 ? \\n\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response7 = chain.invoke({\n",
    "    \"messages\":messages + [HumanMessage(content=\"What math problem did I ask\")],\n",
    "    \"language\":\"English\"\n",
    "})\n",
    "\n",
    "response7.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing this with message_history\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")\n",
    "config5={\"configurable\":{\"session_id\":\"chat5\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I have no memory of past conversations and don't know your name.  \\n\\nIf you'd like to tell me your name, I'd be happy to know! ЁЯШК  \\n\\n\""
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response7 = with_message_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"What is my name\")],\"language\":\"English\"},\n",
    "    config=config5\n",
    ")\n",
    "response7.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generative-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
